NAME: Joseph Lin
EMAIL: jj.lin42@gmail.com
ID: 505111868

INCLUDED FILES:


Q2.3.1 
    Where do you believe most of the cycles are spent in the 1 and 2-thread list tests?
    Why do you believe these to be the most expensive parts of the code?
    Where do you believe most of the time/cycles are being spent in the high-thread spin-lock tests?
    Where do you believe most of the time/cycles are being spent in the high-thread mutex tests?
        In the 1 and 2 thread tests, I believe most of the cycles are being spent doing the list operations rather than lock operations. In the case of low thread runs, the threads do not 
        need to spend as much time waiting for the lock simply because there are less threads that need access. 
        In the high thread spin lock tests, most of the time is probably spent spinning and waiting for the lock to become available. For the mutex tests, the thread does not keep spinning 
        until the lock is available, however, the mutex functions are complex operations that will take longer.

Q2.3.2 
    Where (what lines of code) are consuming most of the cycles when the spin-lock version of the list exerciser is run with a large number of threads?
    Why does this operation become so expensive with large numbers of threads?
        The line 
            else if (opt_s) while (__sync_lock_test_and_set(&spin_lock, 1));
        is consuming the most cycles of code. This becomes more expensive with more threads because the spin lock will be spending more CPU cycles just waiting for the lock to be released.
        
Q2.3.3
    Why does the average lock-wait time rise so dramatically with the number of contending threads?
    Why does the completion time per operation rise (less dramatically) with the number of contending threads?
    How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?
        The lock wait time rises dramatically because there are more threads contending, which means other contending threads have to sit in line before they get their hands on the lock. 
        The completion time, on the other hand, does not rise as dramatically with the number of contending threads because the operation the thread has to complete is still the same and
        there will always be one thread doing the task. 
        It's possible that the wait time per operation goes up faster than the completion time per operation because many threads may have been waiting in the same time slice, resulting in
        a greater total wait time. The completion time per operation is calculated in the parent thread so it doesn't take into account the time threads spend simultaneously waiting for the
        lock to be released.

Q2.3.4
    Explain the change in performance of the synchronized methods as a function of the number of lists.
    Should the throughput continue increasing as the number of lists is further increased? If not, explain why not.
    It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent to the throughput of a single list with fewer (1/N) threads. 
    Does this appear to be true in the above curves? If not, explain why not.
        Throughput increases as the number of lists increases. The throughput should reach some point where increasing the number of lists does not increase throughput where each element
        has its own sublist, so adding more lists would not make a difference. Looking graphs 4 and 5, it does seem to be the case that throughput of an N-way partitioned list is equivalent 
        to the throughput of a single list with 1/N threads. In graph 4, we see that the point with lists=4 and threads=4 has about the same throughput as lists=1 and threads=1. Overall, 
        we see that with the same ratio of threads to sublists, we obtain roughly the same throughput.

